{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11cff105",
   "metadata": {
    "id": "11cff105"
   },
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b65d87",
   "metadata": {
    "id": "06b65d87"
   },
   "source": [
    "In this notebook, you'll implement the **skip-gram** version of the Word2Vec model that was presented in the lecture. Please refer to the slides and to the original paper (https://arxiv.org/abs/1301.3781) whenever needed.\n",
    "\n",
    "We'll use the WikiText2 dataset, which is a collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia. \n",
    "\n",
    "To split the text into words, we shall use the 'basic_english' tokenizer from torchtext (https://pytorch.org/text/stable/index.html). This is a word-level tokenizer that splits a text into a list of English uncased words and punctuation symbols. Note that a special '\\<unk>' token is used whenever an unknown word is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b82c5d03",
   "metadata": {
    "id": "b82c5d03"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data import get_tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "train_iter = WikiText2(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e5595b",
   "metadata": {
    "id": "24e5595b"
   },
   "source": [
    "You should start by building `vocab`, a dictionary containing the vocabulary. The keys will be the words and the values are the corresponding indices, starting from 0. It is a good practice to discard rare words from the vocabulary, so we'll only keep those words that appear at least `MIN_REPS` times.\n",
    "\n",
    "Thus, you should do the following in the cell below:\n",
    "\n",
    "1. Build a `word_count` dictionary containing the number of times that each word appears. For this purpose, you should create an iterator from `train_iter` and iterate on it to get each sequence in the dataset. Each sequence should be split in a list of tokens (words) by calling the `tokenizer`. \n",
    "\n",
    "2. Build a `vocab` dictionary as described above. The `vocab` should only contain valid words that appear at least `MIN_REPS`. We have reserved a special index (-100) for the '\\<unk>' token which you should use for out-of-vocabulary words.\n",
    "    \n",
    "It is also useful to have the inverse mapping from `vocab`, i.e. another dictionary that, given the word index, outputs the corresponding word. We have already built that for you in `vocab_inv`.\n",
    "\n",
    "**Remark:** We could be using `torchtext.vocab`, which facilitates building the `vocab` dictionary and its inverse. For pedagogical reasons, this time you will implement these by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "31bc6a31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31bc6a31",
    "outputId": "0c43a186-9d6a-4fc7-b257-5e9aab7fb112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary has 4098 different words.\n"
     ]
    }
   ],
   "source": [
    "MIN_REPS = 50 \n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "word_count = {}\n",
    "for sequence in train_iter:\n",
    "    tokens = tokenizer(sequence)\n",
    "    for idx, tk in enumerate(tokens):\n",
    "        if tk not in word_count:\n",
    "            word_count[tk] = 1\n",
    "        else:\n",
    "            word_count[tk] += 1\n",
    "vocab = {}\n",
    "idx = 0\n",
    "for tk, count in word_count.items():\n",
    "    if count >= MIN_REPS and tk != \"<unk>\":\n",
    "        vocab[tk] = idx\n",
    "        idx += 1\n",
    "\n",
    "### *** ###\n",
    "vocab['<unk>'] = -100\n",
    "vocab_inv = {val: key for (key, val) in vocab.items()}\n",
    "\n",
    "print(f'Vocabulary has {len(vocab)-1} different words.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vRjPCSH8vdv4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRjPCSH8vdv4",
    "outputId": "a90d4645-95c5-482b-ca37-33e4108167cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=\n",
      "valkyria\n",
      "chronicles\n",
      "iii\n",
      "no\n",
      "3\n",
      "(\n",
      "japanese\n",
      ",\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(vocab_inv.get(i, \"KEY_ERROR\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a959066",
   "metadata": {
    "id": "0a959066"
   },
   "source": [
    "Now it is time to complete the `SkipGramDataset` class by implementing its `__init__` method. This method receives `train_iter`, `vocab`, and the width of the window for the skip gram data. For each word, you will consider all the words that appear up to `window_width` words **before or after** the word, so the **total sequence length will be `2*window_width + 1`**.\n",
    "\n",
    "In this `__init__` method you should build (input, context) pairs for the skip gram model and store them in the list attributes `self.inputs` and `self.contexts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "852cf82c",
   "metadata": {
    "id": "852cf82c"
   },
   "outputs": [],
   "source": [
    "class SkipGramDataset(Dataset):\n",
    "    def __init__(self, train_iter, vocab, window_width):\n",
    "        ### YOUR CODE HERE ###\n",
    "        self.inputs = []\n",
    "        self.contexts = []\n",
    "        for sequence in train_iter:\n",
    "            tokens = tokenizer(sequence)\n",
    "            length = len(tokens)\n",
    "            for i, tk in enumerate(tokens):\n",
    "                if i < window_width or i >= length - window_width:\n",
    "                    continue\n",
    "                if tk not in vocab or tk == \"<unk>\":\n",
    "                    continue\n",
    "                for j in range(i - window_width, i + window_width + 1):\n",
    "                    if j == i:\n",
    "                        continue\n",
    "                    next = tokens[j]\n",
    "                    if next not in vocab or next == \"<unk>\":\n",
    "                        continue\n",
    "                    else:\n",
    "                        self.inputs.append(vocab[tk])\n",
    "                        self.contexts.append(vocab[next])\n",
    "        ### *** ###\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.contexts[index]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92d2b125",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92d2b125",
    "outputId": "3d302f70-9a6c-4a6c-c55f-361d5f22ab05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 10647430 examples.\n"
     ]
    }
   ],
   "source": [
    "WINDOW_WIDTH = 4\n",
    "\n",
    "dataset = SkipGramDataset(train_iter, vocab, WINDOW_WIDTH)\n",
    "print(f'Dataset has {len(dataset)} examples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "zsnCbUrj35vD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsnCbUrj35vD",
    "outputId": "2585009f-875c-468c-84d9-4fa15b3112a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for input in dataset.inputs:\n",
    "    if input < 0:\n",
    "        count += 1\n",
    "\n",
    "for context in dataset.contexts:\n",
    "    if context < 0:\n",
    "        count += 1\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abecafcc",
   "metadata": {
    "id": "abecafcc"
   },
   "source": [
    "Let's look at some word pairs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b25756",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12b25756",
    "outputId": "5a9fc4ae-7a45-4a62-af2e-294e0bf7106b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by developed\n",
      "by and\n",
      "by media\n",
      "by .\n",
      "and game\n",
      "and developed\n",
      "and by\n",
      "and media\n",
      "and .\n",
      "and vision\n",
      "and for\n",
      "media developed\n",
      "media by\n",
      "media and\n",
      "media .\n",
      "media vision\n",
      "media for\n",
      "media the\n",
      ". by\n",
      ". and\n",
      ". media\n",
      ". vision\n",
      ". for\n",
      ". the\n",
      ". playstation\n",
      "vision and\n",
      "vision media\n",
      "vision .\n",
      "vision for\n",
      "vision the\n",
      "vision playstation\n",
      "for and\n",
      "for media\n",
      "for .\n",
      "for vision\n",
      "for the\n",
      "for playstation\n",
      "for .\n",
      "the media\n",
      "the .\n",
      "the vision\n",
      "the for\n",
      "the playstation\n",
      "the .\n",
      "the released\n",
      "playstation .\n",
      "playstation vision\n",
      "playstation for\n",
      "playstation the\n",
      "playstation .\n"
     ]
    }
   ],
   "source": [
    "for i in range(200, 250):\n",
    "    x, y = dataset[i]\n",
    "    x_word = vocab_inv[x]\n",
    "    y_word = vocab_inv[y]\n",
    "    print(x_word, y_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af9b9a",
   "metadata": {
    "id": "b8af9b9a"
   },
   "source": [
    "Let's implement the word2vec model. As you can see from the lecture slides, this model simply consists of an `nn.Embedding` layer mapping word indices to embeddings and a `nn.Linear` projection layer mapping to the vocabulary dimension. As you may already know, you should **not** apply the softmax at the output. The loss function you will use does that for you and in a more numerically stable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11f11333",
   "metadata": {
    "id": "11f11333"
   },
   "outputs": [],
   "source": [
    "class SkipGramModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, embed_max_norm=None):\n",
    "        super().__init__()\n",
    "        ### YOUR CODE HERE ###\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim,\n",
    "                                      max_norm=embed_max_norm)\n",
    "        self.linear = nn.Linear(in_features=embed_dim,\n",
    "                                out_features=vocab_size)       \n",
    "        ### *** ###\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Input:\n",
    "          x: torch.LongTensor - tensor with shape (batch,) containing the indices of the input words\n",
    "        Return value:\n",
    "          logits: torch.FloatTensor - tensor with shape (batch, vocab_size) containing unnormalized probabilities\n",
    "            for each word in the vocabulary\n",
    "        '''\n",
    "        ### YOUR CODE HERE ###\n",
    "        embedded = self.embedding(x)\n",
    "        logits = self.linear(embedded)\n",
    "        ### *** ###\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69c0e6f",
   "metadata": {
    "id": "a69c0e6f"
   },
   "source": [
    "Implement the `fit()` function in the cell below. This function should return two lists, containing the loss and accuracy values over the training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31879987",
   "metadata": {
    "id": "31879987"
   },
   "outputs": [],
   "source": [
    "def fit(model, train_loader, optimizer, **kwargs):\n",
    "    \n",
    "    num_epochs = kwargs.get('num_epochs', 100)\n",
    "    loss_fn = kwargs.get('loss_fn', nn.functional.cross_entropy)\n",
    "    device = kwargs.get('device', torch.device('cpu'))\n",
    "    \n",
    "    model.train()\n",
    "    train_loss_hist, train_acc_hist = [], []\n",
    "    print(\"Entering training phase...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}')\n",
    "        pbar = tqdm(train_loader, total=len(train_loader))\n",
    "        train_loss, train_acc = 0, 0\n",
    "        for x, y in pbar:\n",
    "            ### YOUR CODE HERE ###\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                preds = logits.argmax(dim=1)\n",
    "            acc = (preds == y).float().sum() / ((y != -100).float().sum() + 1e-6)\n",
    "            ### *** ###\n",
    "            train_loss += loss.item()\n",
    "            train_acc += acc.item()\n",
    "            pbar.set_description(f'loss = {loss:.3f} | acc = {acc:.3f}')\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader)\n",
    "        print(f'train loss = {train_loss:.3f} | train acc = {train_acc:.3f}')\n",
    "        train_loss_hist.append(train_loss)\n",
    "        train_acc_hist.append(train_acc)\n",
    "        \n",
    "    return train_loss_hist, train_acc_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da2d63",
   "metadata": {
    "id": "13da2d63"
   },
   "source": [
    "Now we instantiate the model, the optimizer and the dataloader and we're ready to train! As usual, we need to define a few hyperparameters. We set `EMBEDDING_DIM = 300` by default as this was the value used by the authors in the paper, but later you can play around with different values. Limiting the embeddings norm by setting `EMBEDDING_MAX_NORM = 1` is optional, but you can verify empirically that it will yield nicer embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "374c5cd7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "374c5cd7",
    "outputId": "bda5f451-b0a9-451b-8246-b951ff645885",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "EMBEDDING_MAX_NORM = 1\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     DEVICE = torch.device('mps')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print('DEVICE:', DEVICE)\n",
    "\n",
    "model = SkipGramModel(vocab_size=len(vocab)-1, embed_dim=EMBEDDING_DIM,\n",
    "                      embed_max_norm=EMBEDDING_MAX_NORM).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d216b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.6'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab5c13a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ce8d237",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ce8d237",
    "outputId": "8e1c8bdd-d44f-4956-a37b-f3f95b669863",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering training phase...\n",
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss = 6.673 | acc = 0.000: 100%|██████████| 83184/83184 [10:16<00:00, 134.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 6.126 | train acc = 0.084\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss = 5.255 | acc = 0.167: 100%|██████████| 83184/83184 [10:01<00:00, 138.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 5.974 | train acc = 0.088\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss = 5.984 | acc = 0.000: 100%|██████████| 83184/83184 [09:45<00:00, 142.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 5.936 | train acc = 0.088\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss = 7.313 | acc = 0.000: 100%|██████████| 83184/83184 [09:58<00:00, 139.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 5.913 | train acc = 0.088\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss = 5.137 | acc = 0.333: 100%|██████████| 83184/83184 [09:37<00:00, 144.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 5.898 | train acc = 0.088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = fit(model, dataloader, optimizer, num_epochs=NUM_EPOCHS, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37c15eaf",
   "metadata": {
    "id": "37c15eaf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Train loss')\n",
    "plt.plot(range(len(train_loss)), train_loss)\n",
    "plt.show()\n",
    "plt.title('Train accuracy')\n",
    "plt.plot(range(len(train_acc)), train_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c356892",
   "metadata": {
    "id": "3c356892"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'word2vec.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02717b8e",
   "metadata": {
    "id": "02717b8e"
   },
   "source": [
    "Extract the embeddings from the model and normalize them to have unit L2-norm. Store the normalized embeddings in a `np.array` named `embeddings_norm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7354b087",
   "metadata": {
    "id": "7354b087"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "embeddings_norm = np.zeros((len(vocab) - 1, len(vocab) - 1))\n",
    "for idx, token_idx in enumerate(vocab_inv):\n",
    "    if token_idx < 0:\n",
    "        continue\n",
    "    token_idx = torch.tensor(token_idx).to(DEVICE)\n",
    "    embedding = model(token_idx)\n",
    "    embedding /= (embedding**2).sum().sqrt()\n",
    "    embeddings_norm[idx] = embedding.detach().cpu().numpy()\n",
    "### *** ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caf1654",
   "metadata": {
    "id": "5caf1654"
   },
   "source": [
    "Now we'll **visualize the learned embeddings**! Since these are 300-dimensional, they are impossible to visualize directly. First, **we need to project the embeddings into a two- (or three-)dimensional space**. We do this by using the t-Distributed Stochastic Neighbor Embedding algorithm (**t-SNE**, https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf), which usually provides very nice visualizations of high-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0b6b0254",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "0b6b0254",
    "outputId": "b9f43471-54ac-41eb-8802-26dfbb8ffe1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:800: FutureWarning:\n",
      "\n",
      "The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:810: FutureWarning:\n",
      "\n",
      "The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get embeddings\n",
    "embeddings_df = pd.DataFrame(embeddings_norm)\n",
    "\n",
    "# t-SNE transform\n",
    "tsne = TSNE(n_components=2)\n",
    "embeddings_df_trans = tsne.fit_transform(embeddings_df)\n",
    "embeddings_df_trans = pd.DataFrame(embeddings_df_trans)\n",
    "\n",
    "# get token order\n",
    "embeddings_df_trans.index = [vocab_inv[i] for i in range(len(vocab_inv)-1)]\n",
    "\n",
    "# if token is a number\n",
    "is_numeric = embeddings_df_trans.index.str.isnumeric()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b003e5c9",
   "metadata": {
    "id": "b003e5c9"
   },
   "source": [
    "Run the cell below and open the generated file (word2vec_visualization.html) in your browser. Explore the embedding space. You should see semantically related words close to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f4a316bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "f4a316bc",
    "outputId": "383c2317-a158-4d3e-e509-e93ccbad2380"
   },
   "outputs": [],
   "source": [
    "color = np.where(is_numeric, \"green\", \"black\")\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=embeddings_df_trans[0],\n",
    "        y=embeddings_df_trans[1],\n",
    "        mode=\"text\",\n",
    "        text=embeddings_df_trans.index,\n",
    "        textposition=\"middle center\",\n",
    "        textfont=dict(color=color),\n",
    "    )\n",
    ")\n",
    "fig.write_html(\"./word2vec_visualization.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be582110",
   "metadata": {
    "id": "be582110"
   },
   "source": [
    "Implement the function `get_most_similar`, which receives a `word` and outputs a dictionary where the keys are the `topN` words whose embeddings are closer (as measured by the cosine similarity) to the embedding of the `word`. The values of the returned dictionary should be filled with the similarities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2184d5b3",
   "metadata": {},
   "source": [
    "NOTE: What is a cosine similarity? \n",
    "It is [a measure for the similarity of two numerical sequences](https://en.wikipedia.org/wiki/Cosine_similarity), defined as:\n",
    "$${\\displaystyle {\\text{cosine similarity}}=S_{C}(A,B):=\\cos(\\theta )={\\mathbf {A} \\cdot \\mathbf {B}  \\over \\|\\mathbf {A} \\|\\|\\mathbf {B} \\|}={\\frac {\\sum \\limits _{i=1}^{n}{A_{i}B_{i}}}{{\\sqrt {\\sum \\limits _{i=1}^{n}{A_{i}^{2}}}}{\\sqrt {\\sum \\limits _{i=1}^{n}{B_{i}^{2}}}}}},}$$\n",
    "However, since our embeddings have been $L^2$ normalized, this expression reduces to a simple dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "30bf2cbd",
   "metadata": {
    "id": "30bf2cbd"
   },
   "outputs": [],
   "source": [
    "def get_most_similar(word, vocab, vocab_inv, embeddings, topN=1):\n",
    "    ### YOUR CODE HERE ###\n",
    "    if word not in vocab:\n",
    "        raise ValueError(\"Out-of-vocabulary word\")\n",
    "        \n",
    "    embedded_word = embeddings[vocab[word]] # Already normalized\n",
    "    sim_measure = np.zeros(len(vocab) - 1)\n",
    "    for idx, embed in enumerate(embeddings):\n",
    "        # Compute cosine similarity\n",
    "        cos_sim = embedded_word.dot(embed)\n",
    "        sim_measure[idx] = cos_sim\n",
    "    # Remove self-similarity\n",
    "    sim_measure[vocab[word]] = 0.\n",
    "    # Retrieve N most similar\n",
    "    most_similar = np.argpartition(sim_measure, -topN)[-topN:]\n",
    "    topN_dict = {vocab_inv[idx]: sim_measure[idx] for idx in most_similar}\n",
    "    ## *** ###\n",
    "    return topN_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "507022a1",
   "metadata": {
    "id": "48590839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 words most similar to 'mother': {'marriage': 0.9939189618878457, 'childhood': 0.994191462906954, 'sister': 0.9944777641850377, 'husband': 0.998205339347774, 'father': 0.9985799521359424, 'daughter': 0.996377047892695, 'carol': 0.9959251962180061, 'wife': 0.9967699907666896, 'leslie': 0.9957421999576708, 'murder': 0.9949894109524331}\n",
      "\n",
      "Top-10 words most similar to 'portugal': {'frelimo': 0.9925747314761783, 'overseas': 0.9927721249963637, 'conflict': 0.992817159036237, 'arrival': 0.992913178815407, 'jurchen': 0.9931085903008502, 'expedition': 0.9937993791004343, 'leadership': 0.9944367278622491, 'invasion': 0.9950541853516872, 'communist': 0.9943285752144269, 'administration': 0.9939862495269551}\n",
      "\n",
      "Top-10 words most similar to 'queen': {'mary': 0.992428087948326, 'edward': 0.9925483531149006, 'louis': 0.9927012182354644, 'king': 0.9927668705894643, 'bishop': 0.9935678257254625, 'frank': 0.9934954013484225, 'frederick': 0.9947224080485901, 'iv': 0.9935612033469015, 'le': 0.9942780130893147, 'charles': 0.9936445343859798}\n",
      "\n",
      "Top-10 words most similar to 'sports': {'major': 0.9871822163001039, 'association': 0.9913025183085429, 'multi': 0.9896593533034943, 'non': 0.9871984780400574, 'sport': 0.9900843881738937, 'national': 0.9879345556009677, 'amateur': 0.9886983890434301, 'olympic': 0.9916337342197383, 'athletics': 0.9899407155179751, 'international': 0.9906186773344599}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in ['mother', 'portugal', 'queen', 'sports']:\n",
    "    print(f\"Top-10 words most similar to '{word}': {get_most_similar(word, vocab, vocab_inv, embeddings_norm, topN=10)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f97bd2",
   "metadata": {
    "id": "e6f97bd2"
   },
   "source": [
    "## Negative sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56c8d06",
   "metadata": {
    "id": "c56c8d06"
   },
   "source": [
    "Our vocabulary has only ~4k words, so training without negative sampling was doable. However, it is very common to have much larger vocabularies (10^5-10^7 words) where the original word2vec model is much more expensive to train.\n",
    "\n",
    "For this reason, you'll now implement the skip-gram Word2Vec model with negative sampling. You should start by implementing a new dataset class in the cell below, which extends the original `SkipGramDataset`. The `SkipGramDatasetNS` should have the following attributes:\n",
    "1. `inputs: List[int]` - same as before\n",
    "2. `contexts: torch.LongTensor` - tensor with shape `(num_examples, num_neg + 1)` that contains the index of the positive word (true context) and the indices of the negative words, which are sampled from the vocabulary according to the distribution provided in the list `word_probs`. You can use the function `np.random.choice` to do the sampling.\n",
    "3. `labels: torch.FloatTensor` - tensor with shape (num_neg + 1) that is 1 in the position corresponding to the positive word and 0 elsewhere.\n",
    "\n",
    "**Remark:** We could be generating negative examples *on-the-fly* (i.e., in `__getitem__`) instead of generating them only once in `__init__`. This way we would avoid repeating the same negative examples every training epoch, which could improve the results a bit. However, `np.random.choice` is quite slow and therefore on-the-fly generation would slow down training considerably."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de329b2",
   "metadata": {},
   "source": [
    "NOTE: We have not covered this topic in class since there wasn't enough time. However, I found a neat [reference](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/). I will try to complement this notebook with annotations about the principles of negative sampling as needed. [This one](https://analyticsindiamag.com/how-to-use-negative-sampling-with-word2vec-model/) is also great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6a63c779",
   "metadata": {
    "id": "6a63c779"
   },
   "outputs": [],
   "source": [
    "class SkipGramDatasetNS(SkipGramDataset):\n",
    "    def __init__(self, train_iter, vocab, word_probs, window_width, num_neg):\n",
    "        super().__init__(train_iter, vocab, window_width)\n",
    "        ### YOUR CODE HERE ###\n",
    "        train_iter = iter(train_iter)\n",
    "        self.inputs = []\n",
    "        pos_context = []\n",
    "        # Keep track of number of valid examples (we skip OOV words)\n",
    "        num_examples = 0\n",
    "        # Pick input, context pairs as in regular SkipGram\n",
    "        print(\"Generating skip-grams...\")\n",
    "        for sequence in train_iter:\n",
    "            tokens = tokenizer(sequence)\n",
    "            length = len(tokens)\n",
    "            for i, tk in enumerate(tokens):\n",
    "                if tk not in vocab or tk == \"<unk>\":\n",
    "                    continue\n",
    "                # Treat beginning and end of token sequence as special cases\n",
    "                left_idx, right_idx = i - window_width, i + window_width + 1\n",
    "                left_idx = 0 if i < window_width else left_idx\n",
    "                right_idx = length if i > length - (window_width + 1) else right_idx\n",
    "                for j in range(left_idx, right_idx):\n",
    "                    if j == i:\n",
    "                        continue\n",
    "                    next = tokens[j]\n",
    "                    if next not in vocab or next == \"<unk>\":\n",
    "                        continue\n",
    "                    else:\n",
    "                        self.inputs.append(vocab[tk])\n",
    "                        pos_context.append(vocab[next])\n",
    "                        num_examples += 1\n",
    "        print(\"Finished generating skip-grams.\")\n",
    "        self.contexts = torch.LongTensor(np.zeros((num_examples, num_neg + 1)))\n",
    "        # Generate negative contexts\n",
    "        rng = np.random.default_rng(seed=42)\n",
    "        # Need to do it on a loop to avoid repeated words along last axis\n",
    "        print(\"Generating negative samples...\")\n",
    "        neg_context = rng.choice(np.array(len(vocab) - 1), size=(num_examples, num_neg),\n",
    "                                 replace=True, p=word_probs)\n",
    "        self.contexts[:, 1:] = torch.from_numpy(neg_context)\n",
    "        self.contexts[:, 0] = torch.tensor(pos_context)\n",
    "        print(\"Finished generating negative samples.\")\n",
    "        # Mark position of positive context inside contexts LongTensor\n",
    "        temp = np.zeros(num_neg + 1)\n",
    "        temp[0] = 1\n",
    "        self.labels = torch.tensor(temp)\n",
    "        ### *** ###\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        Return values:\n",
    "          input: int - the index of the input word \n",
    "          contexts: torch.LongTensor - tensor with shape (num_neg + 1,) containing the indices of the positive\n",
    "            and negative words\n",
    "          labels: torch.FloatTensor - tensor with binary labels with the same shape as contexts\n",
    "        '''\n",
    "        return self.inputs[index], self.contexts[index], self.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd44624",
   "metadata": {
    "id": "9dd44624"
   },
   "source": [
    "We can think of many distributions to sample our negatives from. The authors of wav2vec found empirically that a good option is to sample negative words $w$ from the distribution $q$ defined by: $$q(w) = \\frac{\\hat{p}(w)^{3/4}}{Z},$$ where $\\hat{p}$ is the distribution of words in the training corpus and $Z$ is a normalization constant (such that $\\sum_{\\forall w \\in V} q(w) = 1$). The fractional exponent (3/4) has a smoothing effect on the distribution, so that we avoid sampling the most frequent words too often.\n",
    "\n",
    "In the cell below, build the list `word_probs` where `word_probs[i]`$= q(w_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6d6ff99d",
   "metadata": {
    "id": "6d6ff99d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n",
      "[8.49302086e-03 7.50272480e-05 7.39827720e-05 ... 9.30942955e-05\n",
      " 7.81321615e-05 7.91579780e-05]\n",
      "4098\n",
      "4099\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "word_count = {}\n",
    "for sequence in train_iter:\n",
    "    tokens = tokenizer(sequence)\n",
    "    for idx, tk in enumerate(tokens):\n",
    "        if tk not in vocab or tk == \"<unk>\":\n",
    "            continue\n",
    "        if tk not in word_count:\n",
    "            word_count[tk] = 1\n",
    "        else:\n",
    "            word_count[tk] += 1\n",
    "word_probs = np.array(list(word_count.values()), dtype=\"float64\")\n",
    "token_count = np.array(list(word_count.values())).sum()\n",
    "word_probs /= token_count # Compute frequency of each token\n",
    "word_probs = word_probs**0.75 # Increase probability of rare tokens\n",
    "word_probs /= word_probs.sum() # Normalize\n",
    "\n",
    "# Sanity check\n",
    "print(word_probs.sum()) # should evaluate to 1\n",
    "print(word_probs)\n",
    "print(word_probs.size) \n",
    "print(len(vocab)) # +1 since includes <unk>\n",
    "### *** ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f466b44",
   "metadata": {
    "id": "4f466b44"
   },
   "source": [
    "Now we instantiate our dataset. We just need to decide the number of negative words to use. A small value (<10) is usually enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6f74b49e",
   "metadata": {
    "id": "6f74b49e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating skip-grams...\n",
      "Finished generating skip-grams.\n",
      "Generating negative samples...\n",
      "Finished generating negative samples.\n",
      "Dataset has 11339212 examples.\n"
     ]
    }
   ],
   "source": [
    "NUM_NEG = 5\n",
    "\n",
    "datasetNS = SkipGramDatasetNS(train_iter, vocab, word_probs, WINDOW_WIDTH, NUM_NEG)\n",
    "print(f'Dataset has {len(datasetNS)} examples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ded6d0",
   "metadata": {
    "tags": [
     "draft"
    ]
   },
   "outputs": [],
   "source": [
    "# Draft code for forming SkipGrams correctly\n",
    "tokens = [\"i\", \"would\", \"like\", \"a\", \"cup\",\n",
    "          \"of\", \"coffee\", \",\", \"please\"]\n",
    "inputs = []\n",
    "contexts = []\n",
    "window_width = 2\n",
    "length = len(tokens)\n",
    "for i, tk in enumerate(tokens):\n",
    "    # Treat beginning and end of token sequence as special cases\n",
    "    left_idx, right_idx = i - window_width, i + window_width + 1\n",
    "    left_idx = 0 if i < window_width else left_idx\n",
    "    right_idx = length if i > length - (window_width + 1) else right_idx\n",
    "    for j in range(left_idx, right_idx):\n",
    "        if j == i:\n",
    "            continue\n",
    "        try:\n",
    "            neighbour = tokens[j]\n",
    "        except IndexError:\n",
    "            print(j, length)\n",
    "        inputs.append(tk)\n",
    "        contexts.append(neighbour)\n",
    "for i in range(len(inputs)):\n",
    "    x, y = inputs[i], contexts[i]\n",
    "    print(f\"{x} {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782ba439",
   "metadata": {
    "id": "782ba439"
   },
   "source": [
    "The model architecture and the `fit` routine also need to be changed. How? That's what you need to think about out now :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e4e2765e",
   "metadata": {
    "id": "e4e2765e"
   },
   "outputs": [],
   "source": [
    "class SkipGramModelNS(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, embed_max_norm=None):\n",
    "        super().__init__()\n",
    "        ### YOUR CODE HERE ###\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim,\n",
    "                                      max_norm=embed_max_norm)\n",
    "        self.linear = nn.Linear(in_features=embed_dim,\n",
    "                                out_features=vocab_size)    \n",
    "        self.vocab_size = vocab_size\n",
    "        ### *** ###\n",
    "    \n",
    "    def forward(self, x, c):\n",
    "        '''\n",
    "        Inputs:\n",
    "          x: torch.LongTensor - tensor with shape (batch,) containing the indices of the input words\n",
    "          c: torch.LongTensor - tensor with shape (batch, num_context) containing the indices of the context words\n",
    "        Return value:\n",
    "          sim: torch.FloatTensor - tensor with shape (batch, num_context) containing the cosine similarities between\n",
    "            the embeddings of x and the embeddings of each context word in c.\n",
    "        '''\n",
    "        ### YOUR CODE HERE ###\n",
    "        batch_size, num_context = c.shape\n",
    "        # Compute dense representation of input\n",
    "        x_embed = self.embedding(x)\n",
    "        x_out = self.linear(x_embed)\n",
    "        # Compute dense representation of each context\n",
    "        # and use it for similarity measure\n",
    "        # Note that first measure corresponds to positive class\n",
    "        # and the others to negative classes\n",
    "        sim = torch.zeros((batch_size, num_context))\n",
    "        for idx in range(num_context):\n",
    "            c_embed = self.embedding(c[:, idx]) \n",
    "            c_out = self.linear(c_embed)\n",
    "            # Store similarity measure with input representation\n",
    "            # Trick to compute dot product over batch\n",
    "            cosine_sim = torch.bmm(x_out.view(batch_size, 1, self.vocab_size),\n",
    "                                   c_out.view(batch_size, self.vocab_size, 1)).squeeze()\n",
    "            cosine_sim /= (c_out**2).sum(dim=1).sqrt()\n",
    "            cosine_sim /= (x_out**2).sum(dim=1).sqrt()\n",
    "            sim[:, idx] = cosine_sim            \n",
    "        ### *** ###\n",
    "        return sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "15839753",
   "metadata": {
    "id": "15839753"
   },
   "outputs": [],
   "source": [
    "def fitNS(model, train_loader, optimizer, **kwargs):\n",
    "    ### YOUR CODE HERE ###\n",
    "    num_epochs = kwargs.get('num_epochs', 100)\n",
    "    device = kwargs.get('device', torch.device('cpu'))\n",
    "    def NSloss(output, target):\n",
    "        pos_loss = -torch.log(torch.sigmoid(output[:, 0]))\n",
    "        neg_loss = -(torch.log(1 - torch.sigmoid(output[:, 1:]))).sum(dim=1)\n",
    "        loss = pos_loss + neg_loss\n",
    "        return loss.mean()\n",
    "    loss_fn = kwargs.get('loss_fn', NSloss)\n",
    "    \n",
    "    model.train() # Activate training mode\n",
    "    train_loss_hist, train_acc_hist = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}')\n",
    "        pbar = tqdm(train_loader, total=len(train_loader))\n",
    "        train_loss, train_acc = 0, 0\n",
    "        for x, c, y in pbar: # inputs, contexts, labels\n",
    "            x, c, y = x.to(device), c.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            sims = model(x, c)\n",
    "            loss = loss_fn(sims, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                preds = sims.argmax(dim=1, keepdim=True).to(device)\n",
    "            acc = (preds == y).float().sum() / ((y != -100).float().sum() + 1e-6)\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_acc += acc.item()\n",
    "            pbar.set_description(f'loss = {loss:.3f} | acc = {acc:.3f}')\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader)\n",
    "        print(f'train loss = {train_loss:.3f} | train acc = {train_acc:.3f}')\n",
    "        train_loss_hist.append(train_loss)\n",
    "        train_acc_hist.append(train_acc)\n",
    "    ### *** ###\n",
    "        \n",
    "    return train_loss_hist, train_acc_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec651a5",
   "metadata": {
    "id": "aec651a5"
   },
   "source": [
    "Now, we're ready to go! Due to negative sampling, this model should train a bit faster than the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "380f37a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "4374a5a6",
   "metadata": {
    "id": "4374a5a6"
   },
   "outputs": [],
   "source": [
    "modelNS = SkipGramModelNS(vocab_size=len(vocab)-1, embed_dim=EMBEDDING_DIM, embed_max_norm=EMBEDDING_MAX_NORM).to(DEVICE)\n",
    "optimizerNS = optim.Adam(modelNS.parameters(), lr=LEARNING_RATE)\n",
    "dataloaderNS = DataLoader(datasetNS, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcb4fba",
   "metadata": {
    "id": "0bcb4fba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss = 4.161 | acc = 0.220:   1%|          | 569/88588 [00:17<41:19, 35.50it/s] "
     ]
    }
   ],
   "source": [
    "train_lossNS, train_accNS = fitNS(modelNS, dataloaderNS, optimizerNS, num_epochs=NUM_EPOCHS, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a026fe",
   "metadata": {
    "id": "60a026fe"
   },
   "outputs": [],
   "source": [
    "plt.title('Train loss (with neg. sampling)')\n",
    "plt.plot(range(len(train_lossNS)), train_lossNS)\n",
    "plt.show()\n",
    "plt.title('Train accuracy (with neg. sampling)')\n",
    "plt.plot(range(len(train_accNS)), train_accNS)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad96b13a",
   "metadata": {
    "id": "ad96b13a"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'word2vecNS.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8559a2ac",
   "metadata": {
    "id": "8559a2ac"
   },
   "source": [
    "Now we repeat the experiments we have done before for the model without negative sampling. You can copy the code for normalizing the embeddings and paste it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c947480",
   "metadata": {
    "id": "1c947480"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "### *** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1506f252",
   "metadata": {
    "id": "1506f252"
   },
   "outputs": [],
   "source": [
    "# get embeddings\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "\n",
    "# t-SNE transform\n",
    "tsne = TSNE(n_components=2)\n",
    "embeddings_df_trans = tsne.fit_transform(embeddings_df)\n",
    "embeddings_df_trans = pd.DataFrame(embeddings_df_trans)\n",
    "\n",
    "# get token order\n",
    "embeddings_df_trans.index = [vocab_inv[i] for i in range(len(vocab_inv)-1)]\n",
    "\n",
    "# if token is a number\n",
    "is_numeric = embeddings_df_trans.index.str.isnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68930eb",
   "metadata": {
    "id": "f68930eb"
   },
   "outputs": [],
   "source": [
    "color = np.where(is_numeric, \"green\", \"black\")\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=embeddings_df_trans[0],\n",
    "        y=embeddings_df_trans[1],\n",
    "        mode=\"text\",\n",
    "        text=embeddings_df_trans.index,\n",
    "        textposition=\"middle center\",\n",
    "        textfont=dict(color=color),\n",
    "    )\n",
    ")\n",
    "fig.write_html(\"./word2vecNS_visualization.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f332a08",
   "metadata": {
    "id": "4f332a08"
   },
   "outputs": [],
   "source": [
    "for word in ['mother', 'portugal', 'queen', 'sports']:\n",
    "    print(f\"Top-10 words most similar to '{word}': {get_most_similar(word, vocab, vocab_inv, embeddings_norm, topN=10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc197a",
   "metadata": {
    "id": "6adc197a"
   },
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55fc753",
   "metadata": {
    "id": "a55fc753"
   },
   "source": [
    "Now you can have some fun finding other interesting relations in the embeddings you have learned. There are also a few hyperparameters that we have defined rather arbitrarily that you can play with.\n",
    "With little effort, you can also implement the **continuous bag-of-words (CBOW)** version of Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f085a",
   "metadata": {
    "id": "f98f085a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ea628a803fd91925100a64391271027fefee9b19b057af296aad7ee8973386a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
